{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc3d36f-f5e4-42cd-a449-7fe6d6ecaf1f",
   "metadata": {},
   "source": [
    "# Padova Grand Tour - Scraped Data Ingester\n",
    "\n",
    "This notebook will read the scraped data stored inside `scraper/results` and generate a `scraped.ttl` turtle file formatted according to our ontology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce87321",
   "metadata": {},
   "source": [
    "Import Json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c34448-20af-4a5a-a268-fc0db733797c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.155485Z",
     "iopub.status.busy": "2022-11-23T10:55:15.154293Z",
     "iopub.status.idle": "2022-11-23T10:55:15.172062Z",
     "shell.execute_reply": "2022-11-23T10:55:15.170293Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "\n",
    "path = str(Path(os.path.abspath((os.getcwd()))).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb271a0-6d98-46ec-9838-2acd7c9c95c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.180814Z",
     "iopub.status.busy": "2022-11-23T10:55:15.179818Z",
     "iopub.status.idle": "2022-11-23T10:55:15.214318Z",
     "shell.execute_reply": "2022-11-23T10:55:15.212589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read Json files\n",
    "with open(path + '/scraper/results/padovamuseicivici.json') as f:\n",
    "    museicivici = json.load(f)\n",
    "\n",
    "with open(path + '/scraper/results/wikipedia-categories.json') as f:\n",
    "    wikicategories = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d2b10",
   "metadata": {},
   "source": [
    "Fix missing/broken data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2632f138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.221936Z",
     "iopub.status.busy": "2022-11-23T10:55:15.221008Z",
     "iopub.status.idle": "2022-11-23T10:55:15.232324Z",
     "shell.execute_reply": "2022-11-23T10:55:15.230373Z"
    }
   },
   "outputs": [],
   "source": [
    "# some missing data\n",
    "manualLocations = {}\n",
    "manualLocations['latitude']=['45°24′42.54″N','45°24′39.46″N','45°24′39.46″N','45°24′41.65″N','45°24′28.25″N']\n",
    "manualLocations['longitude']=['11°52′46.33″E','11°52′48.04″E','11°52′48.04″E','11°52′41.23″E','11°52′36.93″E']\n",
    "\n",
    "# Overlapping museums\n",
    "siteOverlaps = {\n",
    "    'https://padovamusei.it/it/musei/museo-bottacin': 'https://it.wikipedia.org/wiki/Museo_Bottacin'\n",
    "}\n",
    "siteNodes = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbfe7dd",
   "metadata": {},
   "source": [
    "Setup graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54665355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.240800Z",
     "iopub.status.busy": "2022-11-23T10:55:15.239089Z",
     "iopub.status.idle": "2022-11-23T10:55:15.322508Z",
     "shell.execute_reply": "2022-11-23T10:55:15.321266Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF, XSD, schema.org\n",
    "from rdflib.namespace import FOAF, XSD, SDO\n",
    "from rdflib.collection import Collection\n",
    "\n",
    "# Main namespace\n",
    "PGT = Namespace(\"https://padovagrandtour.github.io/entitites#\")\n",
    "# Be careful! the \"simple GEO\" namespace is not the same as the \"advanced GEO\" namespace exported by rdflib\n",
    "GEO = Namespace(\"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "\n",
    "# Saving folder\n",
    "savePath =  path + \"/data/ttlData/\"\n",
    "os.makedirs(savePath, exist_ok=True)\n",
    "\n",
    "\n",
    "# Bind namespaces\n",
    "g = Graph()\n",
    "\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"pgt\", PGT)\n",
    "g.bind(\"sdo\", SDO)\n",
    "g.bind(\"geo\", GEO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b53278",
   "metadata": {},
   "source": [
    "Helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e271ce3-15a0-4f90-9cfb-118ead0c5ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.330332Z",
     "iopub.status.busy": "2022-11-23T10:55:15.329813Z",
     "iopub.status.idle": "2022-11-23T10:55:15.376047Z",
     "shell.execute_reply": "2022-11-23T10:55:15.374559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract data as as the year is roughly referring\n",
    "import roman\n",
    "\n",
    "def parseDate(date):\n",
    "    date = date.replace('Il secolo', 'II secolo')\n",
    "\n",
    "    date = date.replace('sec.', 'sec')\n",
    "    date = date.replace('secolo', 'sec')\n",
    "    date = date.replace('Sec.', 'sec')\n",
    "    date = date.replace('Secolo', 'sec')\n",
    "    date = date.replace('sec', '')\n",
    "    date = date.strip()\n",
    "\n",
    "    date = date.replace('A.C.', 'a.C.')\n",
    "    date = date.replace('a. C.', 'a.C.')\n",
    "    date = date.replace('d.C.', '')\n",
    "    date = date.replace('d.C', '')\n",
    "    date = date.replace(',', '')\n",
    "    date = date.replace('Ll-lll', 'LI-III')\n",
    "    date = date.replace('decenio', 'decennio')\n",
    "\n",
    "    date = re.sub(r\"\\([^)]+\\)\", \"\", date)\n",
    "\n",
    "\n",
    "    date = date.replace('L', 'I')\n",
    "    date = date.replace('Il', 'II')\n",
    "    date = date.replace('lll', 'III')\n",
    "    date = date.replace('ll', 'II')\n",
    "\n",
    "    date = ' '.join(date.split())\n",
    "   \n",
    "\n",
    "    #undetermined or missing\n",
    "    if (date == ''): return float('nan')\n",
    "    \n",
    "    m = re.search('on determi', date)\n",
    "    if m: return float('nan')\n",
    "\n",
    "    # special encoded values\n",
    "    if (date == 'Epoca romana'): return 100\n",
    "    if (date == 'Epoca imperiale'): return 100\n",
    "    if (date == 'Prima età imperiale'): return 40\n",
    "    if (date == '1720-1730 montatura; 1820-1830 pagina'): return 1770\n",
    "    if (date == 'Età tiberio-claudia - II'): return 150\n",
    "    if (date == 'Epoca imperiale o tardo-antica'): return 40\n",
    "    if (date == 'Età romana inizio'): return 40\n",
    "    if (date == 'Tra il 27 a.C. e il 68'): return 40\n",
    "    if (date == 'Tra il II a.C. e il 165 a.C.'): return -190\n",
    "\n",
    "    if (date == 'Metà I - II'): return 180\n",
    "    if (date == 'Ultimo quarto I a.C. - metà I'): return 10\n",
    "    if (date == 'Tra il fine I a.C. e il metà I'): return 40\n",
    "    if (date == 'Fine I a.C. - prima metà I'): return 40\n",
    "    if (date == 'Seconda metà I - II'): return 180\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) a.C. primo quarto$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* -100 + 10)\n",
    "\n",
    "\n",
    "    m = re.search('Nuovo Regno - ([XIV]+?) dinastia', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* 100 + 10)\n",
    "\n",
    "    m = re.search('Fine del I a.C. - inizio del I', date)\n",
    "    if m: return 0\n",
    "\n",
    "    m = re.search('^([XIV]+?)\\s?[/-]\\s?([XIV]+?) fine/inizio$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)))* 100 / 2)    \n",
    "    m = re.search('^Prima metà ([XIV]+?) -prima metà ([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)))* 100 / 2)\n",
    "    m = re.search('^([XIV]+?)\\s?[/-]\\s?([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)))* 100 / 2)    \n",
    "    m = re.search('^([XIV]+?)\\s?[/-]\\s?([XIV]+?) a.C.$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)))* 100 / 2)    \n",
    "    m = re.search('^([XIV]+?)\\s?[/-]\\s?([XIV]+?) a.C. fine/inizio$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)))* 100 / 2)    \n",
    "\n",
    "\n",
    "    m = re.search('Metà I a.C. - metà I', date)\n",
    "    if m: return 0\n",
    "\n",
    "    \n",
    "    m = re.search('^([XIV]+?) a.C. inizio$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* -100 + 10)\n",
    "\n",
    "    m = re.search('^([XIV]+?) inizio$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* +100 - 90)\n",
    "\n",
    "    m = re.search('^Metà ([XIV]+?)$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* 100 - 50)\n",
    "\n",
    "    m = re.search('^Fine ([XIV]+?) fine$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* 100 - 25)\n",
    "    m = re.search('^([XIV]+?) fine$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* 100 - 25)\n",
    "\n",
    "\n",
    "    m = re.search('Primo-ondo decennio ([XIV]+?)$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* 100 - 85)\n",
    "\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?)\\-([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)) )* 100 /2)\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) a.C. prima metà$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* -100 + 25)\n",
    "    m = re.search('^([XIV]+?) a.C. metà$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* -100 + 50)\n",
    "\n",
    "    m = re.search('^([XIV]+?) a.C. onda metà$', date)\n",
    "    if m: return (roman.fromRoman(m.group(1))* -100 + 75)\n",
    "\n",
    "    m = re.search('^([XIV]+?) a.C.\\s?[/-]\\s?([XIV]+?) fine/inizio$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)) )* -100 /2)\n",
    "    m = re.search('^([XIV]+?) a.C.\\s?[/-]\\s?([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) + roman.fromRoman(m.group(2)) )* -100 /2)\n",
    "\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) a.C.$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) )* -100 + 50)\n",
    "\n",
    "    m = re.search('^([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) )* 100 - 50)\n",
    "\n",
    "    m = re.search('Tra il ([0-9]+?) e il ([0-9]+?)', date)\n",
    "    if m: return ((int(m.group(1))  + int(m.group(2)))/2)\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) a.C. fine$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) )* -100 + 90)\n",
    "\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) prima metà$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) )* 100 - 75)\n",
    "\n",
    "\n",
    "    m = re.search('^([0-9]+?) a.C.$', date)\n",
    "    if m: return (((int(m.group(1)) )-1) * -100)\n",
    "\n",
    "    m = re.search('^([0-9]+?)/([0-9]+?)/([0-9]+?)$', date)\n",
    "    if m: return ((int(m.group(1)) - 1) * 100)\n",
    "\n",
    "    m = re.search('^([0-9]+?)\\-([0-9]+?)$', date)\n",
    "    if m: return ((int(m.group(1)) + int(m.group(2)) * 100)/2)\n",
    "\n",
    "    m = re.search('^Post ([0-9]+?)$', date)\n",
    "    if m: return ((int(m.group(1))* 100 ))\n",
    "\n",
    "    m = re.search('^([0-9]+?)$', date)\n",
    "    if m: return ((int(m.group(1)) - 1) * 100)\n",
    "\n",
    "    m = re.search('^([0-9]+?) circa$', date)\n",
    "    if m: return ((int(m.group(1)) - 1) * 100)\n",
    "\n",
    "    m = re.search('^Tra il ([0-9]+?) e il$', date)\n",
    "    if m: return ((int(m.group(1)) * 100))\n",
    "\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 50))\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) primo quarto$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 90))\n",
    "\n",
    "    m = re.search('^([XIV]+?) ondo quarto$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 65))\n",
    "    \n",
    "    m = re.search('^([XIV]+?) terzo quarto$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 40))\n",
    "\n",
    "    m = re.search('^([XIV]+?) ultimo quarto$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 15))\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) fine$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 10))\n",
    "\n",
    "    m = re.search('^Fine ([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 10))\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) onda metà$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100))\n",
    "\n",
    "    m = re.search('^([XIV]+?) metà$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100))\n",
    "\n",
    "\n",
    "    m = re.search('^Metà ([XIV]+?) metà$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100))\n",
    "\n",
    "    m = re.search('^Seconda metà ([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100))\n",
    "\n",
    "    m = re.search('^Dopo la metà del ([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 25))\n",
    "\n",
    "    m = re.search('^Fine ([XIV]+?)$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 -10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    m = re.search('^([XIV]+?) prima metà$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * 100 - 75))\n",
    "\n",
    "    m = re.search('^([XIV]+?) miIIennio a.C. onda metà$', date)\n",
    "    if m: return ((roman.fromRoman(m.group(1)) * -1000 + 750))\n",
    "\n",
    "    # if no matches, print an error\n",
    "    print(\"[ERROR] \" + date)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc62517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.383017Z",
     "iopub.status.busy": "2022-11-23T10:55:15.382604Z",
     "iopub.status.idle": "2022-11-23T10:55:15.389885Z",
     "shell.execute_reply": "2022-11-23T10:55:15.388576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add to graph while doing standard normalizations\n",
    "def addToG(subject, predicate, obj, key, datatype):\n",
    "    try: # Catch keyerrors\n",
    "        if(obj[key] == obj[key]):   # check for NaN values\n",
    "            if(datatype == XSD.string):\n",
    "                g.add((subject, predicate, Literal(obj[key].strip(), datatype=datatype)))    \n",
    "            else:\n",
    "                g.add((subject, predicate, Literal(obj[key], datatype=datatype)))    \n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d219bad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.397034Z",
     "iopub.status.busy": "2022-11-23T10:55:15.396610Z",
     "iopub.status.idle": "2022-11-23T10:55:15.403439Z",
     "shell.execute_reply": "2022-11-23T10:55:15.402179Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert latitude/longitude from degrees to float\n",
    "def deg2float(lat):\n",
    "    deg, minutes, seconds, direction =  re.split('[°′″]', lat)\n",
    "    return (float(deg) + float(minutes)/60 + float(seconds)/(60*60)) * (-1 if direction in ['O', 'S'] else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4b5fc",
   "metadata": {},
   "source": [
    "Main \"populate graph\" loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21029b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:15.411188Z",
     "iopub.status.busy": "2022-11-23T10:55:15.410763Z",
     "iopub.status.idle": "2022-11-23T10:55:16.409989Z",
     "shell.execute_reply": "2022-11-23T10:55:16.408672Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "SITEindex = 0\n",
    "COLLECTIONindex = 0\n",
    "ARTWORKindex = 0\n",
    "\n",
    "\n",
    "for museumURL, museumData in museicivici.items():\n",
    "    # Setup museum node\n",
    "    Museum = URIRef(PGT[\"SITE\" +  str(SITEindex)])\n",
    "    SITEindex = SITEindex + 1\n",
    "    if(museumURL == 'https://cappellascrovegni.padovamusei.it'):\n",
    "        g.add((Museum, PGT['hasCategory'], PGT[\"CSCategoryChurch\"]))\n",
    "    else:\n",
    "        g.add((Museum, PGT['hasCategory'], PGT[\"CSCategoryMuseum\"]))\n",
    "\n",
    "    # Add museum tag to overlaps\n",
    "    if(museumURL in siteOverlaps.keys()):\n",
    "        siteNodes[siteOverlaps[museumURL]] = Museum\n",
    "    # Add museum properties\n",
    "    g.add((Museum, SDO.url, Literal(museumURL, datatype=SDO.URL)))  \n",
    "    g.add((Museum, RDF.type, PGT[\"CulturalSite\"]))\n",
    "\n",
    "    addToG(Museum, SDO.name, museumData, 'name', datatype=XSD.string)\n",
    "    addToG(Museum, SDO.description, museumData, 'description', datatype=RDF.HTML)\n",
    "    addToG(Museum, SDO.image, museumData, 'img', datatype=SDO.URL)\n",
    "    # Location\n",
    "    g.add((Museum, GEO['lat'], Literal(float(deg2float(manualLocations['latitude'][SITEindex -1])), datatype=XSD.float)))  \n",
    "    g.add((Museum, GEO['long'], Literal(float(deg2float(manualLocations['longitude'][SITEindex -1])), datatype=XSD.float)))  \n",
    "\n",
    "\n",
    "\n",
    "    for collectionURL, collectionData in museumData['collections'].items():\n",
    "        # Setup collection node\n",
    "        MCollection = URIRef(PGT[\"COLLECTION\" +  str(COLLECTIONindex)])\n",
    "        COLLECTIONindex = COLLECTIONindex + 1\n",
    "        g.add((MCollection, RDF.type, PGT.Collection))\n",
    "        # Add Collection properties\n",
    "        g.add((MCollection, SDO.url, Literal(collectionURL, datatype=SDO.URL)))\n",
    "        addToG(MCollection, SDO.name, collectionData, 'name', datatype=XSD.string)\n",
    "        addToG(MCollection, SDO.description, collectionData, 'description', datatype=RDF.HTML)\n",
    "        addToG(MCollection, SDO.image, collectionData, 'img', datatype=SDO.URL)\n",
    "\n",
    "\n",
    "\n",
    "        for artworkURL, artworkData in collectionData['artworks'].items():\n",
    "            # Setup artwork node\n",
    "            Artwork = URIRef(PGT[\"ARTWORK\" +  str(ARTWORKindex)])\n",
    "            ARTWORKindex = ARTWORKindex + 1\n",
    "            g.add((Artwork, RDF.type, PGT.Artwork))\n",
    "                        \n",
    "            fields = artworkData['fields']\n",
    "\n",
    "\n",
    "            # Simple fields\n",
    "            g.add((Artwork, SDO.url, Literal(artworkURL, datatype=SDO.URL)))  \n",
    "            g.add((Artwork, PGT['hasCollection'], MCollection)) \n",
    "            g.add((Artwork, PGT['hasSite'], Museum))  \n",
    "            addToG(Artwork, SDO.name, artworkData, 'name', datatype=XSD.string)\n",
    "            addToG(Artwork, SDO.description, artworkData, 'description', datatype=RDF.HTML)\n",
    "            addToG(Artwork, SDO.image, artworkData, 'img', datatype=SDO.URL)\n",
    "            addToG(Artwork, PGT['placing'], fields, 'Collocazione', datatype=XSD.string)\n",
    "            addToG(Artwork, PGT['conservationState'], fields, 'Stato di conservazione', datatype=XSD.string)\n",
    "            addToG(Artwork, SDO.author, fields, 'Autore', datatype=XSD.string)\n",
    "            addToG(Artwork, SDO.material, fields, 'Materiale e Tecnica', datatype=XSD.string)\n",
    "\n",
    "            # Parse date\n",
    "            parsedDate = parseDate(fields['Cronologia'])\n",
    "            if( parsedDate == parsedDate):\n",
    "                g.add((Artwork, PGT['yearCreatedText'], Literal(fields['Cronologia'], datatype=XSD.string)))\n",
    "                g.add((Artwork, PGT['yearCreated'], Literal(parsedDate, datatype=XSD.year)))\n",
    "            # Tags\n",
    "            if(artworkData['tags'] == artworkData['tags']):   # check for NaN values\n",
    "                for tag in artworkData['tags']:\n",
    "                    g.add((Artwork, PGT['tag'], Literal(tag.strip().lower().replace(\"/ \", \"/\"), datatype=XSD.string)))  \n",
    "            # Dimensions\n",
    "            try:\n",
    "                if(fields['Dimensioni'] == fields['Dimensioni']):\n",
    "                    g.add((Artwork, PGT['dimensionsText'], Literal(fields['Dimensioni'], datatype=XSD.string)))\n",
    "                    for (dimName, dimValue) in re.findall(r'([^\\s]+)\\s*:\\s*(\\d+\\.?\\d*)', fields['Dimensioni']):\n",
    "                        dimName = dimName.strip().lower()\n",
    "                        if('larghezza' in dimName):\n",
    "                            g.add((Artwork, PGT['width'], Literal(float(dimValue), datatype=XSD.float)))  \n",
    "                        if('lunghezza' in dimName):\n",
    "                            g.add((Artwork, PGT['length'], Literal(float(dimValue), datatype=XSD.float)))  \n",
    "                        if('altezza' in dimName):\n",
    "                            g.add((Artwork, PGT['height'], Literal(float(dimValue), datatype=XSD.float)))  \n",
    "                        if('diametro' in dimName):\n",
    "                            g.add((Artwork, PGT['diameter'], Literal(float(dimValue), datatype=XSD.float)))  \n",
    "                        if('spessore' in dimName):\n",
    "                            g.add((Artwork, PGT['thickness'], Literal(float(dimValue), datatype=XSD.float)))  \n",
    "                        if('profondità' in dimName):\n",
    "                            g.add((Artwork, PGT['depth'], Literal(float(dimValue), datatype=XSD.float)))  \n",
    "\n",
    "\n",
    "            except: pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964769b1",
   "metadata": {},
   "source": [
    "Add locations and other sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0505706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:16.418419Z",
     "iopub.status.busy": "2022-11-23T10:55:16.417958Z",
     "iopub.status.idle": "2022-11-23T10:55:16.454895Z",
     "shell.execute_reply": "2022-11-23T10:55:16.453575Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (4050894707.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3059/4050894707.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    try: g.add((Site, PGT['hasCategory'], PGT[\"CSCategory\" + categoryNames[categoryURL]))\u001b[0m\n\u001b[0m                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "categoryNames = {\n",
    "    'https://it.wikipedia.org/wiki/Categoria:Musei_di_Padova':'Museum', \n",
    "    'https://it.wikipedia.org/wiki/Categoria:Castelli_di_Padova':'Castle', \n",
    "    'https://it.wikipedia.org/wiki/Categoria:Chiese_di_Padova':'Church', \n",
    "    'https://it.wikipedia.org/wiki/Categoria:Basiliche_di_Padova':'Basilica',\n",
    "    'https://it.wikipedia.org/wiki/Categoria:Mura_e_porte_di_Padova':'WallOrGate',\n",
    "    'https://it.wikipedia.org/wiki/Categoria:Palazzi_di_Padova':'Palace',\n",
    "    'https://it.wikipedia.org/wiki/Categoria:Logge_di_Padova':'Loggia',\n",
    "    'https://it.wikipedia.org/wiki/Categoria:Ponti_di_Padova':'Bridge'\n",
    "}\n",
    "\n",
    "\n",
    "for categoryURL, categoryData in wikicategories.items():\n",
    "    for siteURL, siteData in categoryData.items():\n",
    "        if('andbox' in siteURL): continue\n",
    "        if(siteURL in siteOverlaps.values()):\n",
    "            Site = siteNodes[siteURL]\n",
    "        else:\n",
    "            Site = URIRef(PGT[\"SITE\" +  str(SITEindex)])\n",
    "            SITEindex = SITEindex + 1\n",
    "            g.add((Site, RDF.type, PGT[\"CulturalSite\"]))\n",
    "            # Add a category if a mapping exists\n",
    "            try: g.add((Site, PGT['hasCategory'], PGT[\"CSCategory\" + categoryNames[categoryURL]]))\n",
    "            except: pass\n",
    "\n",
    "        g.add((Site, SDO.url, Literal(siteURL, datatype=SDO.URL)))  \n",
    "        addToG(Site, SDO.name, siteData, 'name', datatype=XSD.string)\n",
    "        addToG(Site, SDO.description, siteData, 'description', datatype=RDF.HTML)\n",
    "        if('latitude' in siteData.keys()):\n",
    "            g.add((Site, GEO['lat'], Literal(float(deg2float(siteData['latitude'])), datatype=XSD.float)))  \n",
    "        if('longitude' in siteData.keys()):\n",
    "            g.add((Site, GEO['long'], Literal(float(deg2float(siteData['longitude'])), datatype=XSD.float)))  \n",
    "\n",
    "        addToG(Site, SDO.image, siteData, 'img', datatype=SDO.URL)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11674b",
   "metadata": {},
   "source": [
    "Save data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a51c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T10:55:16.462614Z",
     "iopub.status.busy": "2022-11-23T10:55:16.462185Z",
     "iopub.status.idle": "2022-11-23T10:55:17.391374Z",
     "shell.execute_reply": "2022-11-23T10:55:17.390438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N5dbf2dacfc2d4bd191adcaae3659c3fd (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination=savePath+\"scraped.ttl\", format='turtle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
